{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7602e4a0-7456-4946-81df-5e749ec9c380",
   "metadata": {},
   "source": [
    "## Modeling functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d2360a90-b090-4815-a91e-4969d1615609",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme(style='whitegrid')\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.metrics import log_loss, roc_auc_score, recall_score, precision_score, f1_score, classification_report, accuracy_score, plot_roc_curve, plot_confusion_matrix, plot_precision_recall_curve\n",
    "\n",
    "def clf_metrics(model,X_test,y_test):\n",
    "    \"\"\"\n",
    "    Returns various classification evaluation metrics\n",
    "    \n",
    "        Parameters:\n",
    "            model ():         ML model to be evaluated\n",
    "            X_test (df):      scaled test data used to evaluate the model\n",
    "            y_test (series):  target data used for evaluating predictions\n",
    "        \n",
    "        Returns:\n",
    "            Classification report and plots of roc curve and confusion matrix\n",
    "            \n",
    "    \n",
    "    \"\"\"\n",
    "    clf_rep = classification_report(y_test, (model.predict(X_test)))\n",
    "    roc = plot_roc_curve(model, X_test, y_test)\n",
    "    mtrx = plot_confusion_matrix(model, X_test, y_test)\n",
    "    \n",
    "    \n",
    "    return clf_rep, roc, mtrx\n",
    "\n",
    "\n",
    "def results_interpret(model, X_train):\n",
    "    \"\"\"\n",
    "    Returns coefficients from logistric regression model\n",
    "    \n",
    "        Parameters:\n",
    "            model ():  ML model to be interpreted\n",
    "            X_train (df): features table used to train the model\n",
    "            \n",
    "        Returns:\n",
    "            table of regression coefficients and interpretation\n",
    "            \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    coefficients = np.hstack((model.intercept_, model.coef[0]))\n",
    "    results = pd.DataFrame(data={'variable': ['intercept'] + list(X_train.columns), 'coefficient': coefficients})\n",
    "        \n",
    "    return results\n",
    "  \n",
    "    \n",
    "    \n",
    "  \n",
    "\n",
    "def weekday_cycle(Day_of_week):\n",
    "    \"\"\"\n",
    "    Converts days of the week into circular points to properly show its cyclical nature\n",
    "    \n",
    "        Parameters:\n",
    "            Day_of_week (int): day of week as a number\n",
    "            \n",
    "        Returns:\n",
    "            Day of the week Sine, and Day of the week Cosine    \n",
    "    \"\"\"\n",
    "        \n",
    "    x = np.sin(Day_of_week * (2 * np.pi/7))\n",
    "    y = np.cos(Day_of_week * (2 * np.pi/7))\n",
    "    \n",
    "    return x,y\n",
    "\n",
    "    \n",
    "def two_hot(x):\n",
    "    \"\"\"\n",
    "    Encodes periods of day into categories\n",
    "    \n",
    "        Parameters:\n",
    "            x (str):  period of day (i.e. morning)\n",
    "    \n",
    "        Returns:\n",
    "            encoded period of day for machine learning\n",
    "        \n",
    "    \"\"\"\n",
    "     \n",
    "    return np.concatenate([\n",
    "        (x == \"morning\") | (x == \"afternoon\"),\n",
    "        (x == \"afternoon\") | (x == \"evening\"),\n",
    "        (x == \"evening\") | (x == \"overnight\"),\n",
    "        (x == \"overnight\") | (x == \"morning\"),\n",
    "    ], axis=1).astype(int)\n",
    "\n",
    "x = np.array([[\"morning\", \"afternoon\", \"evening\", \"night\"]]).T\n",
    "print(x)\n",
    "x = two_hot(x)\n",
    "print(x)  \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def log_model_fit(X, y, split, estimator, parameters, cv):\n",
    "    \"\"\"\n",
    "    Returns a scaled and tuned log regression model\n",
    "    \n",
    "        Parameters:\n",
    "            X(df):              numeric features data table\n",
    "            y(series):          target column\n",
    "            split (float):      split (fraction) for train_test_split\n",
    "            estimator ():       algorithm\n",
    "            parameters (dict):  parameters used for GridSearchCV\n",
    "              eg. param_grid = {'logistic__C': [0.1,1,10], 'logistic__penalty': ['l1', 'l2']}\n",
    "            cv (int):           # of folds for CV\n",
    "              \n",
    "        Returns:\n",
    "            Fitted model      \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=split, stratify=y)\n",
    "    \n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    \n",
    "    X_train_sc = scaler.transform(X_train)\n",
    "    X_test_sc = scaler.transform(X_test)\n",
    "    \n",
    "    grid = GridSearchCV(estimator, param_grid=parameters, cv=cv)\n",
    "    fit_grid = grid.fit(X_train_sc, y_train)\n",
    "    \n",
    "    \n",
    "    return fit_grid\n",
    "    \n",
    "    \n",
    "    \n",
    "def top_categories(X, perc):\n",
    "    \"\"\"\n",
    "    Returns dominant groups in category by %\n",
    "    \n",
    "        Parameters:\n",
    "            X (list):      column of values\n",
    "            perc (float):  threshold for cutoff (percentage)\n",
    "            \n",
    "        Returns:\n",
    "            List of top groups\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    val_list = []\n",
    "    key_list = []\n",
    "    denom = sum(X.values())\n",
    "    \n",
    "    for count, (keys, values) in enumerate(X.items()):\n",
    "        if (sum(val_list)/denom) < perc:\n",
    "            key_list.append(keys)\n",
    "            val_list.append(values)\n",
    "            \n",
    "    return val_list, key_list\n",
    "    \n",
    "    \n",
    "    \n",
    "def clf_threshold(y_predict, y_prob, y_test):\n",
    "    \"\"\"\n",
    "    Returns plot of precision / recall vs threshold\n",
    "    \n",
    "        Parameters:\n",
    "            y_predict(float):  y_predict from fitted model\n",
    "            y_prob(float):     y_probability from fitted model (predict_proba)\n",
    "            y_test(array):     target values from test set\n",
    "            \n",
    "        Output:\n",
    "            Plot      \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, probs_y[:, 1]) \n",
    "\n",
    "    pr_auc = metrics.auc(recall, precision)\n",
    "\n",
    "    plt.title(\"Precision-Recall vs Threshold Chart\")\n",
    "    plt.plot(thresholds, precision[: -1], \"b--\", label=\"Precision\")\n",
    "    plt.plot(thresholds, recall[: -1], \"r--\", label=\"Recall\")\n",
    "    plt.ylabel(\"Precision, Recall\")\n",
    "    plt.xlabel(\"Threshold\")\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.ylim([0,1])\n",
    "\n",
    "    return\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e890b59-ae5c-47bc-8369-f4d6d3725506",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/wjdol/Desktop/LighthouseLabs/Flight_delays/data/flights_cleanDates.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "102cdfcb-c9af-4b00-9647-c93fbaf2e5d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 49133 entries, 0 to 49132\n",
      "Data columns (total 14 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Unnamed: 0          49133 non-null  int64  \n",
      " 1   mkt_unique_carrier  49133 non-null  object \n",
      " 2   origin              49133 non-null  object \n",
      " 3   origin_city         49133 non-null  object \n",
      " 4   dest                49133 non-null  object \n",
      " 5   dest_city           49133 non-null  object \n",
      " 6   distance            49133 non-null  float64\n",
      " 7   fl_date             49133 non-null  object \n",
      " 8   fl_day              49133 non-null  object \n",
      " 9   week_num            49133 non-null  int64  \n",
      " 10  dep_time_of_day     49133 non-null  object \n",
      " 11  arr_time_of_day     49133 non-null  object \n",
      " 12  arr_delay           49133 non-null  float64\n",
      " 13  delay_binary        49133 non-null  float64\n",
      "dtypes: float64(3), int64(2), object(9)\n",
      "memory usage: 5.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c75e230a-16d0-49c8-8cb0-d6f29810292a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>mkt_unique_carrier</th>\n",
       "      <th>origin</th>\n",
       "      <th>origin_city</th>\n",
       "      <th>dest</th>\n",
       "      <th>dest_city</th>\n",
       "      <th>distance</th>\n",
       "      <th>fl_date</th>\n",
       "      <th>fl_day</th>\n",
       "      <th>week_num</th>\n",
       "      <th>dep_time_of_day</th>\n",
       "      <th>arr_time_of_day</th>\n",
       "      <th>arr_delay</th>\n",
       "      <th>delay_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>DL</td>\n",
       "      <td>FLL</td>\n",
       "      <td>Fort Lauderdale</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>581.0</td>\n",
       "      <td>2019-01-13</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>2</td>\n",
       "      <td>evening</td>\n",
       "      <td>evening</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>AA</td>\n",
       "      <td>DCA</td>\n",
       "      <td>Washington</td>\n",
       "      <td>DFW</td>\n",
       "      <td>Dallas/Fort Worth</td>\n",
       "      <td>1192.0</td>\n",
       "      <td>2019-01-14</td>\n",
       "      <td>Monday</td>\n",
       "      <td>3</td>\n",
       "      <td>morning</td>\n",
       "      <td>morning</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AA</td>\n",
       "      <td>ORD</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IND</td>\n",
       "      <td>Indianapolis</td>\n",
       "      <td>177.0</td>\n",
       "      <td>2019-01-10</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>2</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>UA</td>\n",
       "      <td>PIT</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>SFO</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>2254.0</td>\n",
       "      <td>2019-01-11</td>\n",
       "      <td>Friday</td>\n",
       "      <td>2</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>evening</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>DL</td>\n",
       "      <td>MSP</td>\n",
       "      <td>Minneapolis</td>\n",
       "      <td>GFK</td>\n",
       "      <td>Grand Forks</td>\n",
       "      <td>284.0</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>1</td>\n",
       "      <td>evening</td>\n",
       "      <td>overnight</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 mkt_unique_carrier origin      origin_city dest  \\\n",
       "0           0                 DL    FLL  Fort Lauderdale  ATL   \n",
       "1           1                 AA    DCA       Washington  DFW   \n",
       "2           2                 AA    ORD          Chicago  IND   \n",
       "3           3                 UA    PIT       Pittsburgh  SFO   \n",
       "4           4                 DL    MSP      Minneapolis  GFK   \n",
       "\n",
       "           dest_city  distance     fl_date    fl_day  week_num  \\\n",
       "0            Atlanta     581.0  2019-01-13    Sunday         2   \n",
       "1  Dallas/Fort Worth    1192.0  2019-01-14    Monday         3   \n",
       "2       Indianapolis     177.0  2019-01-10  Thursday         2   \n",
       "3      San Francisco    2254.0  2019-01-11    Friday         2   \n",
       "4        Grand Forks     284.0  2019-01-03  Thursday         1   \n",
       "\n",
       "  dep_time_of_day arr_time_of_day  arr_delay  delay_binary  \n",
       "0         evening         evening       -8.0           0.0  \n",
       "1         morning         morning       75.0           1.0  \n",
       "2       afternoon       afternoon       -7.0           0.0  \n",
       "3       afternoon         evening       -7.0           0.0  \n",
       "4         evening       overnight      -15.0           0.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29a7a346-cc02-4802-9dbf-a255b86b90c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df.drop(['Unnamed: 0', 'origin_city', 'dest_city',], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe770433-b472-4425-82b1-b1510e4f2bae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5026baa0-f23d-4162-b876-9fd6e47a77c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d02ec3-5d75-4504-a08a-dd53ae9db856",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c03af6-51c6-48c2-92f5-81e797434f30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LighthouseLabs",
   "language": "python",
   "name": "lighthouselabs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
