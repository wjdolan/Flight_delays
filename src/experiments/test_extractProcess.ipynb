{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract and Process - Flights Test Data 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_vars = \"\"\"\n",
    "- Y **fl_date**: Flight Date (yyyy-mm-dd)\n",
    "- Y **mkt_unique_carrier**: Unique Marketing Carrier Code. When the same code has been used by multiple carriers, a numeric suffix is used for earlier users, for example, PA, PA(1), PA(2). Use this field for analysis across a range of years.\n",
    "- **branded_code_share**: Reporting Carrier Operated or Branded Code Share Partners\n",
    "- Y **mkt_carrier**: Code assigned by IATA and commonly used to identify a carrier. As the same code may have been assigned to different carriers over time, the code is not always unique. For analysis, use the Unique Carrier Code.\n",
    "- **mkt_carrier_fl_num**: Flight Number\n",
    "- Y **op_unique_carrier**: Unique Scheduled Operating Carrier Code. When the same code has been used by multiple carriers, a numeric suffix is used for earlier users,for example, PA, PA(1), PA(2). Use this field for analysis across a range of years.\n",
    "- **tail_num**: Tail Number\n",
    "- **op_carrier_fl_num**: Flight Number\n",
    "- Y **origin_airport_id**: Origin Airport, Airport ID. An identification number assigned by US DOT to identify a unique airport. Use this field for airport analysis across a range of years because an airport can change its airport code and airport codes can be reused.\n",
    "- Y **origin**: Origin Airport\n",
    "- Y **origin_city_name**: Origin Airport, City Name\n",
    "- Y **dest_airport_id**: Destination Airport, Airport ID. An identification number assigned by US DOT to identify a unique airport. Use this field for airport analysis across a range of years because an airport can change its airport code and airport codes can be reused.\n",
    "- Y **dest**: Destination Airport\n",
    "- Y **dest_city_name**: Destination Airport, City Name\n",
    "- Y **crs_dep_time**: CRS Departure Time (local time: hhmm)\n",
    "- Y **crs_arr_time**: CRS Arrival Time (local time: hhmm)\n",
    "- **dup**: Duplicate flag marked Y if the flight is swapped based on Form-3A data\n",
    "- Y **crs_elapsed_time**: CRS Elapsed Time of Flight, in Minutes\n",
    "- **flights**: Number of Flights\n",
    "- Y **distance**: Distance between airports (miles)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_name = '- Y.+\\*'\n",
    "feat_list = re.findall(feat_name, my_vars)\n",
    "\n",
    "feat_list_clean=[]\n",
    "for feat in feat_list:\n",
    "    feat = re.sub(r\"[- Y **]\", \"\", feat)\n",
    "    feat_list_clean.append(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dic = {\n",
    "    'host': '<enter host here>',\n",
    "    'database': '<enter database>',\n",
    "    'user': '<user>',\n",
    "    'port': '<port>',\n",
    "    'password': '<password>'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect(param_dic):\n",
    "    \"\"\" Connect to the PostgreSQL database server \"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        # connect to the PostgreSQL server\n",
    "        print('Connecting to the PostgreSQL database...')\n",
    "        conn = psycopg2.connect(**param_dic)\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "        sys.exit(1) \n",
    "    print(\"Connection successful\")\n",
    "    return conn\n",
    "\n",
    "def postgres_to_df(conn, select_query, column_names):\n",
    "    \"\"\"\n",
    "    Transforms a SELECT query into a pandas dataframe\n",
    "    \"\"\"\n",
    "    cursor = con.cursor()\n",
    "    try:\n",
    "        cursor.execute(select_query)\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(f\"Error: {error}\")\n",
    "        cursor.close()\n",
    "        return 1\n",
    "    \n",
    "    # list of tuples\n",
    "    res_tuples = cursor.fetchall()\n",
    "    cursor.close()\n",
    "\n",
    "    # return to dataframe\n",
    "    df = pd.DataFrame(res_tuples, columns=column_names)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the PostgreSQL database...\n",
      "Connection successful\n"
     ]
    }
   ],
   "source": [
    "con = connect(param_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT fl_date, mkt_unique_carrier, mkt_carrier, \n",
    "op_unique_carrier, origin_airport_id, origin, \n",
    "origin_city_name, dest_airport_id, dest, \n",
    "dest_city_name, crs_dep_time, crs_arr_time, \n",
    "crs_elapsed_time, distance\n",
    "FROM flights_test\n",
    "WHERE fl_date >= '2020-01-01 00:00:00'::timestamp\n",
    "AND fl_date <= '2020-01-07 00:00:00'::timestamp;\n",
    "\"\"\"\n",
    "\n",
    "col_names = ['fl_date', 'mkt_unique_carrier', 'mkt_carrier', \n",
    "'op_unique_carrier', 'origin_airport_id', 'origin', 'origin_city_name', \n",
    "'dest_airport_id', 'dest', 'dest_city_name', 'crs_dep_time', 'crs_arr_time', \n",
    "'crs_elapsed_time', 'distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = postgres_to_df(con, query, col_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dates to datettime\n",
    "df['fl_date'] = pd.to_datetime(df['fl_date'])\n",
    "df['fl_day'] = df['fl_date'].dt.strftime(\"%A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split origin city and state\n",
    "df[['origin_city','origin_state']]=df['origin_city_name'].str.split(',', expand=True)\n",
    "df[['dest_city','dest_state']]=df['dest_city_name'].str.split(',', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert crs_times to datettime \n",
    "# pad front with 0\n",
    "df['crs_dep_hour'] = df['crs_dep_time'].astype(str).str.zfill(4)\n",
    "df['crs_arr_hour'] = df['crs_arr_time'].astype(str).str.zfill(4)\n",
    "# replace 2400 (not recognized by dataframe) to 0000 (midnight)\n",
    "df['crs_dep_hour'].replace('2400', '0000', inplace=True)\n",
    "df['crs_arr_hour'].replace('2400', '0000', inplace=True)\n",
    "# convert to datetimes and extract hour oly\n",
    "df['crs_dep_hour'] = pd.to_datetime(df['crs_dep_hour'], format=\"%H%M\").dt.round('H').dt.hour\n",
    "df['crs_arr_hour'] = pd.to_datetime(df['crs_arr_hour'], format=\"%H%M\").dt.round('H').dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert hour to time of day categorical variables \n",
    "df['dep_tod'] = pd.cut(df['crs_dep_hour'],\n",
    "    bins=[0,6,12,18,24],\n",
    "    labels=['overnight','morning','afternoon','evening'],\n",
    "    right=False,\n",
    "    include_lowest=True)\n",
    "\n",
    "df['arr_tod'] = pd.cut(df['crs_arr_hour'],\n",
    "    bins=[0,6,12,18,24],\n",
    "    labels=['overnight','morning','afternoon','evening'],\n",
    "    right=False,\n",
    "    include_lowest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting week_num \n",
    "df['week_num'] = df['fl_date'].dt.isocalendar().week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fl_date', 'mkt_unique_carrier', 'mkt_carrier', 'op_unique_carrier',\n",
       "       'origin_airport_id', 'origin', 'origin_city_name', 'dest_airport_id',\n",
       "       'dest', 'dest_city_name', 'crs_dep_time', 'crs_arr_time',\n",
       "       'crs_elapsed_time', 'distance', 'fl_day', 'origin_city', 'origin_state',\n",
       "       'dest_city', 'dest_state', 'crs_dep_hour', 'crs_arr_hour', 'dep_tod',\n",
       "       'arr_tod', 'week_num'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract only relevant features\n",
    "df = df[['mkt_unique_carrier','op_unique_carrier','origin',\n",
    "'origin_city','dest','dest_city',\n",
    "'crs_elapsed_time','crs_dep_hour','dep_tod',\n",
    "'crs_arr_hour','arr_tod','distance',\n",
    "'fl_date','fl_day','week_num']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge with cleaned passenger data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that path may be different\n",
    "df_pass = pd.read_csv('data/processed/toJoin_passenger.csv', index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['identifier']= df['op_unique_carrier'] + \"-\" + df['origin'] + \"-\" + df['dest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fl_pass = pd.merge(df, df_pass, left_on='identifier', \n",
    "    right_on='identifier1', how='left').drop('identifier1', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop any missing values\n",
    "df_fl_pass = df_fl_pass.dropna()\n",
    "# drop redundant columns\n",
    "joined_cols_toDrop = ['distance_y', 'dest_y', 'origin_y', 'unique_carrier']\n",
    "df_fl_pass = df_fl_pass.drop(joined_cols_toDrop, axis=1)\n",
    "# rename original columns\n",
    "df_fl_pass = df_fl_pass.rename(columns={'origin_x':'origin','dest_x':'dest','distance_x':'distance'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mkt_unique_carrier', 'op_unique_carrier', 'origin', 'origin_city',\n",
       "       'dest', 'dest_city', 'crs_elapsed_time', 'crs_dep_hour', 'dep_tod',\n",
       "       'crs_arr_hour', 'arr_tod', 'distance', 'fl_date', 'fl_day', 'week_num',\n",
       "       'identifier', 'departures_performed', 'payload', 'passengers',\n",
       "       'freight', 'air_time', 'aircraft_type', 'distance_group'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fl_pass.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract relevant columns \n",
    "df_fl_pass = df_fl_pass[['identifier','mkt_unique_carrier', 'op_unique_carrier',\n",
    "'origin','origin_city','dest',\n",
    "'dest_city','crs_elapsed_time', 'crs_dep_hour', \n",
    "'dep_tod','crs_arr_hour', 'arr_tod',\n",
    "'distance','fl_date', 'fl_day', 'week_num', \n",
    "'departures_performed', 'payload', 'passengers','freight', \n",
    "'air_time', 'distance_group']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifier</th>\n",
       "      <th>mkt_unique_carrier</th>\n",
       "      <th>op_unique_carrier</th>\n",
       "      <th>origin</th>\n",
       "      <th>origin_city</th>\n",
       "      <th>dest</th>\n",
       "      <th>dest_city</th>\n",
       "      <th>crs_elapsed_time</th>\n",
       "      <th>crs_dep_hour</th>\n",
       "      <th>dep_tod</th>\n",
       "      <th>...</th>\n",
       "      <th>distance</th>\n",
       "      <th>fl_date</th>\n",
       "      <th>fl_day</th>\n",
       "      <th>week_num</th>\n",
       "      <th>departures_performed</th>\n",
       "      <th>payload</th>\n",
       "      <th>passengers</th>\n",
       "      <th>freight</th>\n",
       "      <th>air_time</th>\n",
       "      <th>distance_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WN-ONT-SJC</td>\n",
       "      <td>WN</td>\n",
       "      <td>WN</td>\n",
       "      <td>ONT</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>SJC</td>\n",
       "      <td>San Jose</td>\n",
       "      <td>70</td>\n",
       "      <td>20</td>\n",
       "      <td>evening</td>\n",
       "      <td>...</td>\n",
       "      <td>333</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>418600.0</td>\n",
       "      <td>1112.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WN-ONT-SJC</td>\n",
       "      <td>WN</td>\n",
       "      <td>WN</td>\n",
       "      <td>ONT</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>SJC</td>\n",
       "      <td>San Jose</td>\n",
       "      <td>75</td>\n",
       "      <td>14</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>...</td>\n",
       "      <td>333</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>418600.0</td>\n",
       "      <td>1112.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WN-ONT-SJC</td>\n",
       "      <td>WN</td>\n",
       "      <td>WN</td>\n",
       "      <td>ONT</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>SJC</td>\n",
       "      <td>San Jose</td>\n",
       "      <td>80</td>\n",
       "      <td>9</td>\n",
       "      <td>morning</td>\n",
       "      <td>...</td>\n",
       "      <td>333</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>418600.0</td>\n",
       "      <td>1112.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WN-ONT-SJC</td>\n",
       "      <td>WN</td>\n",
       "      <td>WN</td>\n",
       "      <td>ONT</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>SJC</td>\n",
       "      <td>San Jose</td>\n",
       "      <td>75</td>\n",
       "      <td>6</td>\n",
       "      <td>morning</td>\n",
       "      <td>...</td>\n",
       "      <td>333</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>418600.0</td>\n",
       "      <td>1112.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>WN-ONT-SJC</td>\n",
       "      <td>WN</td>\n",
       "      <td>WN</td>\n",
       "      <td>ONT</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>SJC</td>\n",
       "      <td>San Jose</td>\n",
       "      <td>80</td>\n",
       "      <td>16</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>...</td>\n",
       "      <td>333</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>418600.0</td>\n",
       "      <td>1112.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   identifier mkt_unique_carrier op_unique_carrier origin origin_city dest  \\\n",
       "2  WN-ONT-SJC                 WN                WN    ONT     Ontario  SJC   \n",
       "3  WN-ONT-SJC                 WN                WN    ONT     Ontario  SJC   \n",
       "4  WN-ONT-SJC                 WN                WN    ONT     Ontario  SJC   \n",
       "5  WN-ONT-SJC                 WN                WN    ONT     Ontario  SJC   \n",
       "6  WN-ONT-SJC                 WN                WN    ONT     Ontario  SJC   \n",
       "\n",
       "  dest_city  crs_elapsed_time  crs_dep_hour    dep_tod  ...  distance  \\\n",
       "2  San Jose                70            20    evening  ...       333   \n",
       "3  San Jose                75            14  afternoon  ...       333   \n",
       "4  San Jose                80             9    morning  ...       333   \n",
       "5  San Jose                75             6    morning  ...       333   \n",
       "6  San Jose                80            16  afternoon  ...       333   \n",
       "\n",
       "     fl_date     fl_day week_num departures_performed   payload  passengers  \\\n",
       "2 2020-01-01  Wednesday        1                 13.0  418600.0      1112.0   \n",
       "3 2020-01-01  Wednesday        1                 13.0  418600.0      1112.0   \n",
       "4 2020-01-01  Wednesday        1                 13.0  418600.0      1112.0   \n",
       "5 2020-01-01  Wednesday        1                 13.0  418600.0      1112.0   \n",
       "6 2020-01-01  Wednesday        1                 13.0  418600.0      1112.0   \n",
       "\n",
       "   freight  air_time  distance_group  \n",
       "2      5.0     720.0             1.0  \n",
       "3      5.0     720.0             1.0  \n",
       "4      5.0     720.0             1.0  \n",
       "5      5.0     720.0             1.0  \n",
       "6      5.0     720.0             1.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fl_pass.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge with cleaned Fuel Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fuel = pd.read_csv('data/processed/toJoin_fuel.csv', index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fpf = pd.merge(df_fl_pass, df_fuel, left_on='op_unique_carrier',\n",
    "right_on='unique_carrier', how='left').drop('unique_carrier', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop missing fuel data\n",
    "df_fpf.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge with cleaned Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather = pd.read_csv('data/processed/weather2020_cleaned.csv', index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fpf['weather_id']=df_fpf['fl_date'].astype(str) + \"-\" + df_fpf['origin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flw = pd.merge(df_fpf, df_weather, left_on='weather_id', right_on='date_orig_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flw = df_flw.groupby(['origin_city','fl_date']).apply(lambda x: x.ffill().bfill())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flw.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flw=df_flw[['mkt_unique_carrier', 'origin','origin_city',\n",
    "    'dest', 'dest_city', 'crs_elapsed_time','crs_dep_hour',\n",
    "    'dep_tod', 'crs_arr_hour', 'arr_tod', 'distance', 'distance_group', \n",
    "    'fl_date', 'fl_day', 'week_num', 'departures_performed', 'payload', \n",
    "    'passengers', 'freight', 'sdomt_gallons', 'tdomt_gallons','sdomt_cost', \n",
    "    'tdomt_cost', 'AWND','PRCP', 'SNOW', 'SNWD', 'TAVG']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flw.to_csv('test_flights_complete_raw_7day.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lhl_env38",
   "language": "python",
   "name": "lhl_env38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
